# FleetPulse GenAI Chatbot Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# AI PROVIDER CONFIGURATION
# =============================================================================

# Primary AI provider to use (openai, anthropic, google, azure, ollama)
GENAI_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=

# Anthropic Configuration  
ANTHROPIC_API_KEY=

# Google Gemini Configuration
GOOGLE_API_KEY=

# Azure OpenAI Configuration
AZURE_OPENAI_KEY=
AZURE_OPENAI_ENDPOINT=

# Ollama (Local AI) Configuration
OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# FLEETPULSE INTEGRATION
# =============================================================================

# FleetPulse backend API URL
FLEETPULSE_API_URL=http://localhost:8000

# FleetPulse MCP server path
FLEETPULSE_MCP_SERVER=./fleetpulse-mcp

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Streamlit server configuration
STREAMLIT_SERVER_PORT=8501

# Logging configuration
LOG_LEVEL=INFO
ENABLE_DEBUG=false

# Security
SECRET_KEY=dev-secret-key-change-in-production

# Database configuration
DATABASE_URL=sqlite:///fleetpulse_chat.db

# =============================================================================
# OPTIONAL FEATURES
# =============================================================================

# Redis caching (if using redis profile)
REDIS_URL=redis://localhost:6379

# Enable experimental features
ENABLE_EXPERIMENTAL_FEATURES=false

# Rate limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=60

# Model configuration defaults
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000